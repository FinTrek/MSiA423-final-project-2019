{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read datasets\n",
    "application = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/application_train.csv')\n",
    "bureau = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/bureau.csv')\n",
    "bureau_bal = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/bureau_balance.csv')\n",
    "prev_app = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/previous_application.csv')\n",
    "pos = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/POS_CASH_balance.csv')\n",
    "install = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/installments_payments.csv')\n",
    "credit = pd.read_csv('/Users/zhangyueying/Desktop/S_Analytics_Value_Chain/project/home-credit-default-risk/credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    \"\"\"One-hot encoding for categorical columns with get_dummies\n",
    "    Args: \n",
    "        df (dataframe): dataframe of data\n",
    "        nan_as_category (boolean, optional): whether to set NA as a category, default to be True\n",
    "    Return:\n",
    "        df (dataframe): dataframe with categorical variable as separate columns\n",
    "        new_columns (list): list of new columns added\n",
    "    \"\"\"\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Application dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def application_feature(df):\n",
    "    ''' Feature engineer for application dataset\n",
    "    Args: \n",
    "        df (dataframe): dataframe of application_train\n",
    "    Returns: \n",
    "        df (dataframe): dataframe of application_train with additional features\n",
    "    '''\n",
    "    \n",
    "    # Remove applications with XNA CODE_GENDER\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']  \n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # One-hot encoding\n",
    "    df, cat_cols = one_hot_encoder(df, False)\n",
    "    \n",
    "    # replace DAYS_EMPLOYED: 365243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Engineer new features (percentage)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Bureau dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bureau_feature(bureau, bureau_bal):\n",
    "    '''Feature engineer for bureau and bureau_balance datasets\n",
    "    Args: \n",
    "        bureau (dataframe): dataframe of bureau \n",
    "        bureau_bal (dataframe): dataframe of bureau_balance\n",
    "    Returns: \n",
    "        bureau_agg (dataframe): dataframe of bureau with features aggregated by unique id of applicants\n",
    "    '''\n",
    "    \n",
    "    # One-hot encoding\n",
    "    bureau_bal, bb_cat = one_hot_encoder(bureau_bal, False)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, False)\n",
    "    \n",
    "    # Perform aggregations on bureau_balance and merge with bureau\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bureau_bal.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau_all = pd.merge(bureau, bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['mean'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'CREDIT_DAY_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM': ['mean'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['mean'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean'],\n",
    "        'AMT_ANNUITY': ['max', 'mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "    }\n",
    "    \n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    # Aggregate by application id and rename columns\n",
    "    bureau_agg = bureau_all.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])  \n",
    "    \n",
    "    # Only aggregate features of active credits records\n",
    "    active = bureau_all[bureau_all['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = pd.merge(bureau_agg, active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # Only aggregate features of closed credits records\n",
    "    closed = bureau_all[bureau_all['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = pd.merge(bureau_agg, closed_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    bureau_agg = bureau_agg.reset_index()\n",
    "\n",
    "    return bureau_agg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Previous application dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prev_app_feature(prev_app):\n",
    "    \"\"\" Feature engineer for previous application dataset\n",
    "    Args:\n",
    "        prev_app (dataframe): dataframe of previous application\n",
    "    Return:\n",
    "        prev_agg (dataframe): dataframe with aggregated features of previous application by applicant id\n",
    "    \"\"\"\n",
    "    \n",
    "    # One-hot encoding\n",
    "    prev_app, cat_cols = one_hot_encoder(prev_app, False)\n",
    "    \n",
    "    # Replace Days 365243 values -> nan\n",
    "    prev_app['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev_app['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev_app['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev_app['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev_app['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    \n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev_app['APP_CREDIT_PERC'] = prev_app['AMT_APPLICATION'] / prev_app['AMT_CREDIT']\n",
    "    \n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['mean'],\n",
    "        'AMT_APPLICATION': ['mean'],\n",
    "        'AMT_CREDIT': ['mean'],\n",
    "        'APP_CREDIT_PERC': ['mean'],\n",
    "        'AMT_DOWN_PAYMENT': ['mean'],\n",
    "        'AMT_GOODS_PRICE': ['mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['mean'],\n",
    "        'DAYS_DECISION': ['mean'],\n",
    "        'CNT_PAYMENT': ['mean'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    # Aggregate features\n",
    "    prev_agg = prev_app.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    \n",
    "    # Only aggregate features of approved applications records\n",
    "    approved = prev_app[prev_app['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = pd.merge(prev_agg, approved_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    # Only aggregate features of refused applications records\n",
    "    refused = prev_app[prev_app['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = pd.merge(prev_agg, refused_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    prev_agg = prev_agg.reset_index()\n",
    "\n",
    "    return prev_agg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Installment payment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def install_feature(install):\n",
    "    \"\"\"Feature engineer for installment dataset\n",
    "    Args:\n",
    "        install (dataframe): dataframe of installment\n",
    "    Return:\n",
    "        install_agg (dataframe): dataframe with aggregated features of installment by applicant id\n",
    "    \"\"\"\n",
    "    # One-hot encoding\n",
    "    install, cat_cols = one_hot_encoder(install, False)\n",
    "    \n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    install['PAYMENT_PERC'] = install['AMT_PAYMENT'] / install['AMT_INSTALMENT']\n",
    "    install['PAYMENT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    install['DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\n",
    "    install['DBD'] = install['DAYS_INSTALMENT'] - install['DAYS_ENTRY_PAYMENT']\n",
    "    install['DPD'] = install['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    install['DBD'] = install['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    \n",
    "    # Numeric features\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['mean'],\n",
    "        'DBD': ['mean'],\n",
    "        'PAYMENT_PERC': ['mean'],\n",
    "        'PAYMENT_DIFF': ['mean'],\n",
    "        'AMT_INSTALMENT': ['mean'],\n",
    "        'AMT_PAYMENT': ['mean'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['mean']\n",
    "    }\n",
    "    \n",
    "    # Categorical features\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "        \n",
    "    # Feature aggregation by applicant id\n",
    "    install_agg = install.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    install_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in install_agg.columns.tolist()])\n",
    "    \n",
    "    # Count installments accounts\n",
    "    install_agg['INSTAL_COUNT'] = install.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    install_agg = install_agg.reset_index()\n",
    "\n",
    "    return install_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 POS cash balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_feature(pos):\n",
    "    \"\"\"Feature engineer for POS cash balance dataset\n",
    "    Args:\n",
    "        pos (dataframe): dataframe of POS cash balance dataset\n",
    "    Returen:\n",
    "        pos_agg (dataframe): dataframe with aggregated features of POS cash balance by applicant id\n",
    "    \"\"\"\n",
    "    \n",
    "    # One-hot encoding\n",
    "    pos, cat_cols = one_hot_encoder(pos, False)\n",
    "    \n",
    "    # Numeric and categorical aggregation\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['mean'],\n",
    "        'SK_DPD': ['mean'],\n",
    "        'SK_DPD_DEF': ['mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    # Feature aggregation by applicant id\n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    \n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    pos_agg = pos_agg.reset_index()\n",
    "    \n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Credit card balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def credit_feature(credit):\n",
    "    \"\"\"Feature engineer for credit card balance dataset\n",
    "    Args:\n",
    "        credit (dataframe): dataframe of credit card balance\n",
    "    Return:\n",
    "        credit_agg (dataframe): dataframe with aggregated features of credit cart balance by applicant id\n",
    "    \"\"\"\n",
    "    \n",
    "    # One-hot encoding\n",
    "    credit, cat_cols = one_hot_encoder(credit, False)\n",
    "    \n",
    "    # Feature aggregations by applicant id\n",
    "    credit.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    credit_agg = credit.groupby('SK_ID_CURR').agg(['mean'])\n",
    "    credit_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in credit_agg.columns.tolist()])\n",
    "    \n",
    "    # Count credit card lines\n",
    "    credit_agg['CC_COUNT'] = credit.groupby('SK_ID_CURR').size()\n",
    "    \n",
    "    creidt_agg = credit_agg.reset_index()\n",
    "    \n",
    "    return credit_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data and save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(307507, 537)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge aggregated datasets and save to csv\n",
    "df = application_feature(application)\n",
    "df = pd.merge(df, bureau_feature(bureau, bureau_bal), how='left', on='SK_ID_CURR')\n",
    "df = pd.merge(df, prev_app_feature(prev_app), how='left', on='SK_ID_CURR')\n",
    "df = pd.merge(df, install_feature(install), how='left', on='SK_ID_CURR')\n",
    "df = pd.merge(df, pos_feature(pos), how='left', on='SK_ID_CURR')\n",
    "df = pd.merge(df, credit_feature(credit), how='left', on='SK_ID_CURR')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
